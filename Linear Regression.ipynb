{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models to predict ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "friends = pd.read_csv('transcripts and metadata/friends_mastersheet.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_prod</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode Number</th>\n",
       "      <th>Episode_Title</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Director</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Votes</th>\n",
       "      <th>match</th>\n",
       "      <th>...</th>\n",
       "      <th>Phoebe</th>\n",
       "      <th>Ross</th>\n",
       "      <th>Rachel</th>\n",
       "      <th>Carol</th>\n",
       "      <th>Susan</th>\n",
       "      <th>Janice</th>\n",
       "      <th>Mike</th>\n",
       "      <th>Gunther</th>\n",
       "      <th>Ben</th>\n",
       "      <th>Emily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The One Where Monica Gets a Roommate: The Pilot</td>\n",
       "      <td>22</td>\n",
       "      <td>Monica and the gang introduce Rachel to the \"r...</td>\n",
       "      <td>James Burrows</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7440</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061248</td>\n",
       "      <td>0.144114</td>\n",
       "      <td>0.155643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>The One with the Sonogram at the End</td>\n",
       "      <td>22</td>\n",
       "      <td>Ross finds out his ex-wife is pregnant. Rachel...</td>\n",
       "      <td>James Burrows</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4888</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.248342</td>\n",
       "      <td>0.165269</td>\n",
       "      <td>0.088068</td>\n",
       "      <td>0.044696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>The One with the Thumb</td>\n",
       "      <td>22</td>\n",
       "      <td>Monica becomes irritated when everyone likes h...</td>\n",
       "      <td>James Burrows</td>\n",
       "      <td>8.2</td>\n",
       "      <td>4605</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145415</td>\n",
       "      <td>0.125624</td>\n",
       "      <td>0.102383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>The One with George Stephanopoulos</td>\n",
       "      <td>22</td>\n",
       "      <td>Joey and Chandler take Ross to a hockey game t...</td>\n",
       "      <td>James Burrows</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4468</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111161</td>\n",
       "      <td>0.151849</td>\n",
       "      <td>0.162042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>The One with the East German Laundry Detergent</td>\n",
       "      <td>22</td>\n",
       "      <td>Eager to spend time with Rachel, Ross pretends...</td>\n",
       "      <td>Pamela Fryman</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4438</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095007</td>\n",
       "      <td>0.150061</td>\n",
       "      <td>0.141764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_prod  Season  Episode Number  \\\n",
       "0          1994       1               1   \n",
       "1          1994       1               2   \n",
       "2          1994       1               3   \n",
       "3          1994       1               4   \n",
       "4          1994       1               5   \n",
       "\n",
       "                                     Episode_Title  Duration  \\\n",
       "0  The One Where Monica Gets a Roommate: The Pilot        22   \n",
       "1             The One with the Sonogram at the End        22   \n",
       "2                           The One with the Thumb        22   \n",
       "3               The One with George Stephanopoulos        22   \n",
       "4   The One with the East German Laundry Detergent        22   \n",
       "\n",
       "                                             Summary       Director  Stars  \\\n",
       "0  Monica and the gang introduce Rachel to the \"r...  James Burrows    8.3   \n",
       "1  Ross finds out his ex-wife is pregnant. Rachel...  James Burrows    8.1   \n",
       "2  Monica becomes irritated when everyone likes h...  James Burrows    8.2   \n",
       "3  Joey and Chandler take Ross to a hockey game t...  James Burrows    8.1   \n",
       "4  Eager to spend time with Rachel, Ross pretends...  Pamela Fryman    8.5   \n",
       "\n",
       "   Votes  match  ...    Phoebe      Ross    Rachel     Carol     Susan  \\\n",
       "0   7440     11  ...  0.061248  0.144114  0.155643  0.000000  0.000000   \n",
       "1   4888     12  ...  0.061500  0.248342  0.165269  0.088068  0.044696   \n",
       "2   4605     13  ...  0.145415  0.125624  0.102383  0.000000  0.000000   \n",
       "3   4468     14  ...  0.111161  0.151849  0.162042  0.000000  0.000000   \n",
       "4   4438     15  ...  0.095007  0.150061  0.141764  0.000000  0.000000   \n",
       "\n",
       "     Janice  Mike  Gunther  Ben  Emily  \n",
       "0  0.000000   0.0      0.0  0.0    0.0  \n",
       "1  0.000000   0.0      0.0  0.0    0.0  \n",
       "2  0.000000   0.0      0.0  0.0    0.0  \n",
       "3  0.000000   0.0      0.0  0.0    0.0  \n",
       "4  0.047483   0.0      0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultlist = [['model', 'LOOCV mean score', 'std']]\n",
    "books = pd.read_csv('books/friends_books_topics_model.csv', index_col=0)\n",
    "sb = pd.read_csv('scriptbase/friends_scriptbase_topics.csv', index_col=0)\n",
    "friends_no_topics = pd.read_csv('transcripts and metadata/friends_mastersheet.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dummy baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3113667508113955 0.24655333378118335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "X = friends.text\n",
    "y = friends.Stars\n",
    "\n",
    "vect = TfidfVectorizer()\n",
    "reg = DummyRegressor(strategy=\"mean\")\n",
    "pipe = make_pipeline(vect, reg)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "resultlist.append(['dummy_baseline', np.mean(scores), np.std(scores)])\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.32209667011984083 0.27848673086034265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "X = friends.text\n",
    "y = friends.Stars\n",
    "\n",
    "vect = TfidfVectorizer(max_features=5000)\n",
    "reg = LinearRegression()\n",
    "pipe = make_pipeline(vect, reg)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "resultlist.append(['BOW_baseline', np.mean(scores), np.std(scores)])\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plane       0.822873\n",
       "bam         0.715183\n",
       "la          0.617973\n",
       "dessert     0.584831\n",
       "backup      0.517409\n",
       "              ...   \n",
       "sperm      -0.448818\n",
       "climb      -0.488773\n",
       "everest    -0.495282\n",
       "audition   -0.644059\n",
       "vows       -1.060876\n",
       "Name: Coefficients, Length: 5000, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = model[:-1].get_feature_names_out()\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model[-1].coef_,\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "\n",
    "coefs[\"Coefficients\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['Gary Halvorson',        \n",
    "'Kevin Bright',          \n",
    "'Michael Lembeck',       \n",
    "'James Burrows',           \n",
    "'Gail Mancuso',           \n",
    "'Peter Bonerz',            \n",
    "'David Schwimmer',         \n",
    "'Ben Weiss']\n",
    "\n",
    "def direr(wow):\n",
    "    if wow not in lst:\n",
    "        wow = wow.replace(wow,'Other')\n",
    "    return wow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.31045740095235536 0.2520076439096313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "standardscaler__Duration                   7.327942e-02\n",
       "standardscaler__Ross                       6.348915e-02\n",
       "standardscaler__Year_of_prod               5.674526e-02\n",
       "standardscaler__Monica                     3.224115e-02\n",
       "standardscaler__Janice                     2.630090e-02\n",
       "standardscaler__Rachel                     2.171353e-02\n",
       "standardscaler__Susan                      5.199015e-03\n",
       "standardscaler__Emily                      4.954355e-03\n",
       "standardscaler__Phoebe                     3.096629e-03\n",
       "standardscaler__Joey                      -3.279206e-03\n",
       "standardscaler__Ben                       -5.451320e-03\n",
       "standardscaler__Chandler                  -1.023249e-02\n",
       "standardscaler__Mike                      -1.480190e-02\n",
       "standardscaler__Episode Number            -2.506571e-02\n",
       "standardscaler__Gunther                   -2.997079e-02\n",
       "standardscaler__Carol                     -4.312124e-02\n",
       "standardscaler__Season                    -5.107228e-02\n",
       "onehotencoder__Director_David Schwimmer   -4.247393e+11\n",
       "onehotencoder__Director_Ben Weiss         -4.247393e+11\n",
       "onehotencoder__Director_Peter Bonerz      -4.632152e+11\n",
       "onehotencoder__Director_Gail Mancuso      -4.980910e+11\n",
       "onehotencoder__Director_James Burrows     -5.144106e+11\n",
       "onehotencoder__Director_Michael Lembeck   -6.372968e+11\n",
       "onehotencoder__Director_Other             -8.139188e+11\n",
       "onehotencoder__Director_Kevin Bright      -8.857288e+11\n",
       "onehotencoder__Director_Gary Halvorson    -8.857288e+11\n",
       "Name: Coefficients, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "X = friends_no_topics.drop(columns=['Summary', 'Episode_Title', 'Stars', 'Votes', 'text', 'match', 'len in words', 'len_prep'])\n",
    "X.Director = X.Director.apply(direr)\n",
    "y = friends_no_topics.Stars\n",
    "\n",
    "reg = LinearRegression()\n",
    "hot = OneHotEncoder()\n",
    "scal = StandardScaler()\n",
    "\n",
    "categorical_features = X.select_dtypes(include=\"object\").columns\n",
    "integer_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "prep = make_column_transformer((hot, categorical_features),\n",
    "                                (scal, integer_features))\n",
    "\n",
    "pipe = make_pipeline(prep,reg)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "resultlist.append(['no_topic_baseline', np.mean(scores), np.std(scores)])\n",
    "\n",
    "model = pipe.fit(X, y)\n",
    "\n",
    "feature_names = model[:-1].get_feature_names_out()\n",
    "\n",
    "X_preprocessed = pd.DataFrame(\n",
    "    model[:-1].transform(X), columns=feature_names\n",
    ")\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model[-1].coef_* X_preprocessed.std(axis=0),\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "\n",
    "coefs[\"Coefficients\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### features + tfidf, no topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3827187959279087 0.31705072714911003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = friends_no_topics.drop(columns=['Summary', 'Episode_Title', 'Stars', 'Votes', 'match', 'len in words', 'len_prep'])\n",
    "X.Director = X.Director.apply(direr)\n",
    "y = friends_no_topics.Stars\n",
    "\n",
    "reg = LinearRegression()\n",
    "hot = OneHotEncoder()\n",
    "scal = StandardScaler()\n",
    "vect = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "categorical_features = [X.select_dtypes(include=\"object\").columns[0]]\n",
    "integer_features= X.select_dtypes(exclude=\"object\").columns\n",
    "text_features = X.select_dtypes(include=\"object\").columns[1]\n",
    "\n",
    "prep = make_column_transformer((hot, categorical_features),\n",
    "                                (scal, integer_features),\n",
    "                                (vect, text_features),\n",
    "                               remainder='passthrough')\n",
    "\n",
    "pipe = make_pipeline(prep,reg)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "resultlist.append(['no_topic_tf_idf_baseline', np.mean(scores), np.std(scores)])\n",
    "\n",
    "# model = pipe.fit(X, y)\n",
    "\n",
    "# feature_names = model[:-1].get_feature_names_out()\n",
    "\n",
    "# X_preprocessed = pd.DataFrame(\n",
    "#     model[:-1].transform(X), columns=feature_names\n",
    "# )\n",
    "\n",
    "# coefs = pd.DataFrame(\n",
    "#     model[-1].coef_* X_preprocessed.std(axis=0),\n",
    "#     columns=[\"Coefficients\"],\n",
    "#     index=feature_names,\n",
    "# )\n",
    "\n",
    "# coefs[\"Coefficients\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year_of_prod', 'Season', 'Episode Number', 'Duration', 'Director',\n",
       "       'text', 'Monica', 'Joey', 'Chandler', 'Phoebe', 'Ross', 'Rachel',\n",
       "       'Carol', 'Susan', 'Janice', 'Mike', 'Gunther', 'Ben', 'Emily'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Books corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9603450892037377 0.9452001763789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "standardscaler__Duration                0.128057\n",
       "standardscaler__t250                    0.127984\n",
       "standardscaler__t113                    0.125014\n",
       "onehotencoder__Director_Kevin Bright    0.109744\n",
       "standardscaler__t49                     0.107743\n",
       "                                          ...   \n",
       "standardscaler__t15                    -0.113250\n",
       "standardscaler__t8                     -0.121338\n",
       "onehotencoder__Director_Other          -0.131412\n",
       "standardscaler__t127                   -0.150214\n",
       "standardscaler__Monica                 -0.196894\n",
       "Name: Coefficients, Length: 326, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "X = books.drop(columns=['Summary', 'Episode_Title', 'Stars', 'Votes', 'text', 'match', 'len in words', 'len_prep'])\n",
    "X.Director = X.Director.apply(direr)\n",
    "y = books.Stars\n",
    "\n",
    "reg = LinearRegression()\n",
    "hot = OneHotEncoder()\n",
    "scal = StandardScaler()\n",
    "\n",
    "categorical_features = X.select_dtypes(include=\"object\").columns\n",
    "integer_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "prep = make_column_transformer((hot, categorical_features),\n",
    "                                (scal, integer_features))\n",
    "\n",
    "pipe = make_pipeline(prep,reg)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "resultlist.append(['books_all_topics', np.mean(scores), np.std(scores)])\n",
    "\n",
    "model = pipe.fit(X, y)\n",
    "\n",
    "feature_names = model[:-1].get_feature_names_out()\n",
    "\n",
    "X_preprocessed = pd.DataFrame(\n",
    "    model[:-1].transform(X), columns=feature_names\n",
    ")\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model[-1].coef_* X_preprocessed.std(axis=0),\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "\n",
    "coefs[\"Coefficients\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scriptbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6151407057359037 0.4791936825021369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "standardscaler__t144                    0.124055\n",
       "standardscaler__t163                    0.113698\n",
       "onehotencoder__Director_Kevin Bright    0.112174\n",
       "standardscaler__t122                    0.095668\n",
       "standardscaler__Duration                0.095617\n",
       "                                          ...   \n",
       "standardscaler__t69                    -0.093749\n",
       "standardscaler__t264                   -0.096200\n",
       "onehotencoder__Director_Other          -0.123167\n",
       "standardscaler__t185                   -0.124983\n",
       "standardscaler__Monica                 -0.223561\n",
       "Name: Coefficients, Length: 326, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "X = sb.drop(columns=['Summary', 'Episode_Title', 'Votes', 'text', 'match', 'Stars', 'len in words', 'len_prep'])\n",
    "X.Director = X.Director.apply(direr)\n",
    "y = sb.Stars\n",
    "\n",
    "reg = LinearRegression()\n",
    "hot = OneHotEncoder()\n",
    "scal = StandardScaler()\n",
    "\n",
    "categorical_features = X.select_dtypes(include=\"object\").columns\n",
    "integer_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "prep = make_column_transformer((hot, categorical_features),\n",
    "                                (scal, integer_features))\n",
    "\n",
    "pipe = make_pipeline(prep,reg)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "resultlist.append(['sc_all_topics', np.mean(scores), np.std(scores)])\n",
    "\n",
    "model = pipe.fit(X, y)\n",
    "\n",
    "feature_names = model[:-1].get_feature_names_out()\n",
    "\n",
    "X_preprocessed = pd.DataFrame(\n",
    "    model[:-1].transform(X), columns=feature_names\n",
    ")\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model[-1].coef_* X_preprocessed.std(axis=0),\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "\n",
    "coefs[\"Coefficients\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_best_50 = ['t83', 't188', 't274', 't230', 't273', 't204', 't196',\n",
    "       't176', 't7', 't120', 't151', 't258', 't139', 't70', 't110', 't97',\n",
    "       't235', 't282', 't104', 't62', 't245', 't80', 't171', 't115', 't270',\n",
    "       't109', 't150', 't269', 't158', 't203', 't59', 't295', 't175', 't51',\n",
    "       't166', 't113', 't285', 't299', 't286', 't88', 't127', 't69', 't222',\n",
    "       't272', 't34', 't58', 't153', 't271', 't259', 't73']\n",
    "\n",
    "to_drop = [f't{i}' for i in range(0,300) if f't{i}' not in books_best_50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5091832.472855382 78056308.62585586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "standardscaler__Duration                   0.080130\n",
       "standardscaler__t34                        0.071589\n",
       "standardscaler__t113                       0.065143\n",
       "standardscaler__t73                        0.064742\n",
       "onehotencoder__Director_Michael Lembeck    0.063624\n",
       "                                             ...   \n",
       "standardscaler__t62                       -0.044050\n",
       "standardscaler__t110                      -0.046785\n",
       "standardscaler__t158                      -0.050534\n",
       "standardscaler__t151                      -0.056205\n",
       "standardscaler__t59                       -0.060578\n",
       "Name: Coefficients, Length: 76, dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "columns = ['Summary', 'Episode_Title', 'Stars', 'Votes', 'text', 'match', 'len in words', 'len_prep'] + to_drop\n",
    "\n",
    "X = books.drop(columns=columns)\n",
    "X.Director = X.Director.apply(direr)\n",
    "y = books.Stars\n",
    "\n",
    "reg = LinearRegression()\n",
    "hot = OneHotEncoder()\n",
    "scal = StandardScaler()\n",
    "\n",
    "categorical_features = X.select_dtypes(include=\"object\").columns\n",
    "integer_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "prep = make_column_transformer((hot, categorical_features),\n",
    "                                (scal, integer_features))\n",
    "\n",
    "pipe = make_pipeline(prep,reg)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "resultlist.append(['books_50_topics', np.mean(scores), np.std(scores)])\n",
    "\n",
    "model = pipe.fit(X, y)\n",
    "\n",
    "feature_names = model[:-1].get_feature_names_out()\n",
    "\n",
    "X_preprocessed = pd.DataFrame(\n",
    "    model[:-1].transform(X), columns=feature_names\n",
    ")\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model[-1].coef_* X_preprocessed.std(axis=0),\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "\n",
    "coefs[\"Coefficients\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scriptbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_best_50 = ['t134', 't103', 't12', 't194', 't276', 't35', 't180',\n",
    "       't222', 't32', 't191', 't299', 't64', 't202', 't288', 't275', 't260',\n",
    "       't84', 't182', 't165', 't210', 't90', 't204', 't255', 't217', 't239',\n",
    "       't205', 't26', 't86', 't7', 't119', 't296', 't67', 't265', 't152',\n",
    "       't128', 't72', 't250', 't242', 't287', 't190', 't57', 't44', 't17',\n",
    "       't132', 't189', 't240', 't193', 't21', 't138', 't130']\n",
    "\n",
    "to_drop = [f't{i}' for i in range(0,300) if f't{i}' not in sb_best_50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.29842354294531614 0.24172291941277052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "standardscaler__Year_of_prod             0.267696\n",
       "standardscaler__Duration                 0.070331\n",
       "standardscaler__t103                     0.051990\n",
       "standardscaler__t130                     0.049365\n",
       "onehotencoder__Director_James Burrows    0.047437\n",
       "                                           ...   \n",
       "standardscaler__t250                    -0.059349\n",
       "standardscaler__t35                     -0.059957\n",
       "standardscaler__t288                    -0.065644\n",
       "standardscaler__t191                    -0.092622\n",
       "standardscaler__Season                  -0.252367\n",
       "Name: Coefficients, Length: 76, dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "columns = ['Summary', 'Episode_Title', 'Stars', 'Votes', 'text', 'match', 'len in words', 'len_prep'] + to_drop\n",
    "\n",
    "X = sb.drop(columns=columns)\n",
    "X.Director = X.Director.apply(direr)\n",
    "y = books.Stars\n",
    "\n",
    "reg = LinearRegression()\n",
    "hot = OneHotEncoder()\n",
    "scal = StandardScaler()\n",
    "\n",
    "categorical_features = X.select_dtypes(include=\"object\").columns\n",
    "integer_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "prep = make_column_transformer((hot, categorical_features),\n",
    "                                (scal, integer_features))\n",
    "\n",
    "pipe = make_pipeline(prep,reg)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "resultlist.append(['sb_50_topics', np.mean(scores), np.std(scores)])\n",
    "\n",
    "model = pipe.fit(X, y)\n",
    "\n",
    "feature_names = model[:-1].get_feature_names_out()\n",
    "\n",
    "X_preprocessed = pd.DataFrame(\n",
    "    model[:-1].transform(X), columns=feature_names\n",
    ")\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model[-1].coef_* X_preprocessed.std(axis=0),\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "\n",
    "coefs[\"Coefficients\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_best_25 = ['t83', 't188', 't274', 't230', 't273', 't204', 't196',\n",
    "'t176', 't7', 't120', 't151', 't258', 't139', 't70', 't110', 't97',\n",
    "'t235', 't282', 't104', 't62', 't245', 't80', 't171', 't115', 't270']\n",
    "\n",
    "to_drop = [f't{i}' for i in range(0,300) if f't{i}' not in books_best_25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3114153715736398 0.2630541759549018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "standardscaler__Year_of_prod               0.089218\n",
       "standardscaler__Duration                   0.074765\n",
       "onehotencoder__Director_Kevin Bright       0.054542\n",
       "standardscaler__t273                       0.048128\n",
       "standardscaler__t235                       0.040072\n",
       "onehotencoder__Director_Michael Lembeck    0.039455\n",
       "standardscaler__Ross                       0.039346\n",
       "standardscaler__Phoebe                     0.033669\n",
       "standardscaler__Janice                     0.031512\n",
       "onehotencoder__Director_James Burrows      0.022269\n",
       "standardscaler__Rachel                     0.017430\n",
       "standardscaler__t80                        0.012307\n",
       "standardscaler__t83                        0.008797\n",
       "standardscaler__Susan                      0.004825\n",
       "onehotencoder__Director_David Schwimmer    0.002227\n",
       "standardscaler__Monica                     0.001637\n",
       "standardscaler__Ben                       -0.000678\n",
       "standardscaler__Emily                     -0.002008\n",
       "standardscaler__Mike                      -0.002063\n",
       "standardscaler__t171                      -0.003543\n",
       "standardscaler__t104                      -0.003601\n",
       "onehotencoder__Director_Gary Halvorson    -0.005807\n",
       "standardscaler__t245                      -0.007043\n",
       "onehotencoder__Director_Other             -0.007255\n",
       "standardscaler__Joey                      -0.007543\n",
       "standardscaler__t282                      -0.007817\n",
       "standardscaler__t115                      -0.007900\n",
       "standardscaler__t139                      -0.008015\n",
       "standardscaler__Chandler                  -0.010346\n",
       "onehotencoder__Director_Peter Bonerz      -0.012532\n",
       "standardscaler__t97                       -0.015462\n",
       "standardscaler__t70                       -0.016617\n",
       "standardscaler__t274                      -0.020560\n",
       "onehotencoder__Director_Ben Weiss         -0.022884\n",
       "standardscaler__t7                        -0.024674\n",
       "standardscaler__t230                      -0.025679\n",
       "standardscaler__Gunther                   -0.028762\n",
       "standardscaler__Episode Number            -0.029075\n",
       "standardscaler__Carol                     -0.030879\n",
       "standardscaler__t188                      -0.032353\n",
       "standardscaler__t196                      -0.032917\n",
       "standardscaler__t258                      -0.034444\n",
       "standardscaler__t176                      -0.035769\n",
       "onehotencoder__Director_Gail Mancuso      -0.037666\n",
       "standardscaler__t110                      -0.042444\n",
       "standardscaler__t270                      -0.045567\n",
       "standardscaler__t62                       -0.047586\n",
       "standardscaler__t151                      -0.047640\n",
       "standardscaler__t120                      -0.048168\n",
       "standardscaler__t204                      -0.054426\n",
       "standardscaler__Season                    -0.097733\n",
       "Name: Coefficients, dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "columns = ['Summary', 'Episode_Title', 'Stars', 'Votes', 'text', 'match', 'len in words', 'len_prep'] + to_drop\n",
    "\n",
    "X = books.drop(columns=columns)\n",
    "X.Director = X.Director.apply(direr)\n",
    "y = books.Stars\n",
    "\n",
    "reg = LinearRegression()\n",
    "hot = OneHotEncoder()\n",
    "scal = StandardScaler()\n",
    "\n",
    "categorical_features = X.select_dtypes(include=\"object\").columns\n",
    "integer_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "prep = make_column_transformer((hot, categorical_features),\n",
    "                                (scal, integer_features))\n",
    "\n",
    "pipe = make_pipeline(prep,reg)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "resultlist.append(['books_25_topics', np.mean(scores), np.std(scores)])\n",
    "\n",
    "model = pipe.fit(X, y)\n",
    "\n",
    "feature_names = model[:-1].get_feature_names_out()\n",
    "\n",
    "X_preprocessed = pd.DataFrame(\n",
    "    model[:-1].transform(X), columns=feature_names\n",
    ")\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model[-1].coef_* X_preprocessed.std(axis=0),\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "\n",
    "coefs[\"Coefficients\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scriptbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_best_25 = ['t134', 't103', 't12', 't194', 't276', 't35', 't180',\n",
    "       't222', 't32', 't191', 't299', 't64', 't202', 't288', 't275', 't260',\n",
    "       't84', 't182', 't165', 't210', 't90', 't204', 't255', 't217', 't239']\n",
    "\n",
    "to_drop = [f't{i}' for i in range(0,300) if f't{i}' not in sb_best_25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2974797918025092 0.2315328201205982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "standardscaler__Year_of_prod               0.175997\n",
       "standardscaler__Duration                   0.093107\n",
       "standardscaler__t12                        0.065964\n",
       "standardscaler__t204                       0.060286\n",
       "standardscaler__Phoebe                     0.041857\n",
       "standardscaler__t255                       0.040320\n",
       "standardscaler__t134                       0.040178\n",
       "standardscaler__t182                       0.036322\n",
       "standardscaler__t103                       0.036162\n",
       "standardscaler__Janice                     0.034240\n",
       "standardscaler__Ross                       0.034126\n",
       "standardscaler__t260                       0.025455\n",
       "standardscaler__Ben                        0.024957\n",
       "onehotencoder__Director_James Burrows      0.023801\n",
       "standardscaler__t165                       0.020922\n",
       "onehotencoder__Director_Kevin Bright       0.020815\n",
       "standardscaler__Monica                     0.020462\n",
       "onehotencoder__Director_Michael Lembeck    0.018144\n",
       "standardscaler__Rachel                     0.015454\n",
       "standardscaler__t299                       0.013355\n",
       "onehotencoder__Director_David Schwimmer    0.009850\n",
       "standardscaler__Emily                      0.009309\n",
       "onehotencoder__Director_Peter Bonerz       0.005308\n",
       "standardscaler__t210                      -0.003569\n",
       "standardscaler__Susan                     -0.006605\n",
       "standardscaler__Gunther                   -0.008834\n",
       "standardscaler__Mike                      -0.009604\n",
       "onehotencoder__Director_Gary Halvorson    -0.009986\n",
       "standardscaler__t194                      -0.013502\n",
       "standardscaler__t275                      -0.014800\n",
       "onehotencoder__Director_Ben Weiss         -0.016383\n",
       "standardscaler__t276                      -0.021553\n",
       "standardscaler__Chandler                  -0.021763\n",
       "onehotencoder__Director_Gail Mancuso      -0.023268\n",
       "standardscaler__t180                      -0.023549\n",
       "standardscaler__t64                       -0.027043\n",
       "standardscaler__Joey                      -0.028737\n",
       "onehotencoder__Director_Other             -0.029568\n",
       "standardscaler__Carol                     -0.032374\n",
       "standardscaler__t222                      -0.034815\n",
       "standardscaler__Episode Number            -0.036228\n",
       "standardscaler__t84                       -0.040977\n",
       "standardscaler__t239                      -0.043993\n",
       "standardscaler__t32                       -0.044603\n",
       "standardscaler__t90                       -0.046639\n",
       "standardscaler__t202                      -0.051808\n",
       "standardscaler__t35                       -0.052920\n",
       "standardscaler__t217                      -0.060440\n",
       "standardscaler__t288                      -0.070418\n",
       "standardscaler__t191                      -0.083640\n",
       "standardscaler__Season                    -0.170232\n",
       "Name: Coefficients, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "columns = ['Summary', 'Episode_Title', 'Stars', 'Votes', 'text', 'match', 'len in words', 'len_prep'] + to_drop\n",
    "\n",
    "X = sb.drop(columns=columns)\n",
    "X.Director = X.Director.apply(direr)\n",
    "y = books.Stars\n",
    "\n",
    "reg = LinearRegression()\n",
    "hot = OneHotEncoder()\n",
    "scal = StandardScaler()\n",
    "\n",
    "categorical_features = X.select_dtypes(include=\"object\").columns\n",
    "integer_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "prep = make_column_transformer((hot, categorical_features),\n",
    "                                (scal, integer_features))\n",
    "\n",
    "pipe = make_pipeline(prep,reg)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "resultlist.append(['sb_25_topics', np.mean(scores), np.std(scores)])\n",
    "\n",
    "model = pipe.fit(X, y)\n",
    "\n",
    "feature_names = model[:-1].get_feature_names_out()\n",
    "\n",
    "X_preprocessed = pd.DataFrame(\n",
    "    model[:-1].transform(X), columns=feature_names\n",
    ")\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model[-1].coef_* X_preprocessed.std(axis=0),\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "\n",
    "coefs[\"Coefficients\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_best_25 = ['t134', 't103', 't12', 't194', 't276', 't35', 't180',\n",
    "       't222', 't32', 't191', 't299', 't64', 't202', 't288', 't275', 't260',\n",
    "       't84', 't182', 't165', 't210', 't90', 't204', 't255', 't217', 't239']\n",
    "\n",
    "to_drop = [f't{i}' for i in range(0,300) if f't{i}' not in sb_best_25[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3225936685541604 0.26939307682496816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "standardscaler__Duration                   0.077861\n",
       "onehotencoder__Director_Kevin Bright       0.074790\n",
       "standardscaler__Ross                       0.067757\n",
       "standardscaler__Monica                     0.035341\n",
       "standardscaler__Rachel                     0.030315\n",
       "standardscaler__t180                       0.029250\n",
       "standardscaler__t134                       0.028703\n",
       "onehotencoder__Director_Michael Lembeck    0.027042\n",
       "standardscaler__Janice                     0.025601\n",
       "standardscaler__t191                       0.021194\n",
       "standardscaler__t12                        0.016842\n",
       "standardscaler__Year_of_prod               0.016097\n",
       "onehotencoder__Director_David Schwimmer    0.012326\n",
       "onehotencoder__Director_James Burrows      0.011413\n",
       "standardscaler__t276                       0.009943\n",
       "standardscaler__Susan                      0.009228\n",
       "standardscaler__Phoebe                     0.007119\n",
       "standardscaler__Joey                       0.004133\n",
       "standardscaler__t103                       0.002510\n",
       "standardscaler__Emily                      0.001843\n",
       "onehotencoder__Director_Gary Halvorson    -0.001940\n",
       "standardscaler__Ben                       -0.002424\n",
       "standardscaler__Chandler                  -0.011536\n",
       "standardscaler__t32                       -0.013465\n",
       "standardscaler__Mike                      -0.013915\n",
       "standardscaler__Season                    -0.015490\n",
       "standardscaler__t194                      -0.016720\n",
       "onehotencoder__Director_Ben Weiss         -0.017220\n",
       "standardscaler__t222                      -0.018889\n",
       "onehotencoder__Director_Other             -0.020499\n",
       "standardscaler__Episode Number            -0.021377\n",
       "onehotencoder__Director_Gail Mancuso      -0.023414\n",
       "standardscaler__Gunther                   -0.028994\n",
       "onehotencoder__Director_Peter Bonerz      -0.029253\n",
       "standardscaler__t35                       -0.037709\n",
       "standardscaler__Carol                     -0.046710\n",
       "Name: Coefficients, dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "columns = ['Summary', 'Episode_Title', 'Stars', 'Votes', 'text', 'match', 'len in words', 'len_prep'] + to_drop\n",
    "\n",
    "X = books.drop(columns=columns)\n",
    "X.Director = X.Director.apply(direr)\n",
    "y = books.Stars\n",
    "\n",
    "reg = LinearRegression()\n",
    "hot = OneHotEncoder()\n",
    "scal = StandardScaler()\n",
    "\n",
    "categorical_features = X.select_dtypes(include=\"object\").columns\n",
    "integer_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "prep = make_column_transformer((hot, categorical_features),\n",
    "                                (scal, integer_features))\n",
    "\n",
    "pipe = make_pipeline(prep,reg)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "resultlist.append(['books_10_topics', np.mean(scores), np.std(scores)])\n",
    "\n",
    "model = pipe.fit(X, y)\n",
    "\n",
    "feature_names = model[:-1].get_feature_names_out()\n",
    "\n",
    "X_preprocessed = pd.DataFrame(\n",
    "    model[:-1].transform(X), columns=feature_names\n",
    ")\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model[-1].coef_* X_preprocessed.std(axis=0),\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "\n",
    "coefs[\"Coefficients\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scriptbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3038873936801926 0.23943307322039978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "standardscaler__Duration                   0.083394\n",
       "standardscaler__t12                        0.068854\n",
       "standardscaler__Ross                       0.058842\n",
       "standardscaler__t134                       0.054272\n",
       "onehotencoder__Director_Kevin Bright       0.050282\n",
       "standardscaler__Janice                     0.034728\n",
       "standardscaler__t103                       0.031219\n",
       "standardscaler__Year_of_prod               0.031183\n",
       "onehotencoder__Director_Michael Lembeck    0.026734\n",
       "onehotencoder__Director_James Burrows      0.023358\n",
       "standardscaler__Rachel                     0.021272\n",
       "standardscaler__Monica                     0.016815\n",
       "standardscaler__Phoebe                     0.015975\n",
       "onehotencoder__Director_Gary Halvorson     0.005538\n",
       "standardscaler__Mike                       0.004083\n",
       "onehotencoder__Director_David Schwimmer    0.002160\n",
       "standardscaler__Ben                        0.002017\n",
       "standardscaler__Emily                      0.000616\n",
       "standardscaler__Gunther                   -0.003349\n",
       "onehotencoder__Director_Peter Bonerz      -0.009281\n",
       "standardscaler__Susan                     -0.009761\n",
       "standardscaler__Chandler                  -0.010227\n",
       "onehotencoder__Director_Other             -0.010413\n",
       "standardscaler__t194                      -0.016660\n",
       "standardscaler__Episode Number            -0.018377\n",
       "standardscaler__Season                    -0.019550\n",
       "onehotencoder__Director_Ben Weiss         -0.021528\n",
       "standardscaler__t222                      -0.022035\n",
       "standardscaler__Carol                     -0.025876\n",
       "standardscaler__Joey                      -0.031588\n",
       "standardscaler__t180                      -0.033223\n",
       "onehotencoder__Director_Gail Mancuso      -0.035838\n",
       "standardscaler__t32                       -0.039403\n",
       "standardscaler__t35                       -0.039956\n",
       "standardscaler__t276                      -0.049320\n",
       "standardscaler__t191                      -0.078175\n",
       "Name: Coefficients, dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb_best_25 = ['t134', 't103', 't12', 't194', 't276', 't35', 't180',\n",
    "       't222', 't32', 't191', 't299', 't64', 't202', 't288', 't275', 't260',\n",
    "       't84', 't182', 't165', 't210', 't90', 't204', 't255', 't217', 't239']\n",
    "\n",
    "to_drop = [f't{i}' for i in range(0,300) if f't{i}' not in sb_best_25[:10]]\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "columns = ['Summary', 'Episode_Title', 'Stars', 'Votes', 'text', 'match', 'len in words', 'len_prep'] + to_drop\n",
    "\n",
    "X = sb.drop(columns=columns)\n",
    "X.Director = X.Director.apply(direr)\n",
    "y = books.Stars\n",
    "\n",
    "reg = LinearRegression()\n",
    "hot = OneHotEncoder()\n",
    "scal = StandardScaler()\n",
    "\n",
    "categorical_features = X.select_dtypes(include=\"object\").columns\n",
    "integer_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "prep = make_column_transformer((hot, categorical_features),\n",
    "                                (scal, integer_features))\n",
    "\n",
    "pipe = make_pipeline(prep,reg)\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=cv, scoring = 'neg_root_mean_squared_error')\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "resultlist.append(['sb_10_topics', np.mean(scores), np.std(scores)])\n",
    "\n",
    "model = pipe.fit(X, y)\n",
    "\n",
    "feature_names = model[:-1].get_feature_names_out()\n",
    "\n",
    "X_preprocessed = pd.DataFrame(\n",
    "    model[:-1].transform(X), columns=feature_names\n",
    ")\n",
    "\n",
    "coefs = pd.DataFrame(\n",
    "    model[-1].coef_* X_preprocessed.std(axis=0),\n",
    "    columns=[\"Coefficients\"],\n",
    "    index=feature_names,\n",
    ")\n",
    "\n",
    "coefs[\"Coefficients\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['model', 'LOOCV mean score', 'std'],\n",
       " ['dummy_baseline', -0.3113667508113955, 0.24655333378118335],\n",
       " ['BOW_baseline', -0.32209667011984083, 0.27848673086034265],\n",
       " ['no_topic_baseline', -0.31045740095235536, 0.2520076439096313],\n",
       " ['no_topic_tf_idf_baseline', -0.3827187959279087, 0.31705072714911003],\n",
       " ['books_all_topics', -0.9603450892037377, 0.9452001763789],\n",
       " ['sc_all_topics', -0.6151407057359037, 0.4791936825021369],\n",
       " ['books_50_topics', -5091832.472855382, 78056308.62585586],\n",
       " ['sb_50_topics', -0.29842354294531614, 0.24172291941277052],\n",
       " ['books_25_topics', -0.3114153715736398, 0.2630541759549018],\n",
       " ['sb_25_topics', -0.2974797918025092, 0.2315328201205982],\n",
       " ['books_10_topics', -0.3225936685541604, 0.26939307682496816],\n",
       " ['sb_10_topics', -0.3038873936801926, 0.23943307322039978]]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db3ad00c254152fbd946dfe3ddf750e2d6dd1f511dd85499e770b0c6b301697a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
